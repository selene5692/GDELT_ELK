input {
  file {
    path => "/usr/share/logstash/data/*.json"  # JSON files in the mounted ingestion folder
    start_position => "beginning"              # Read new files from the beginning
    sincedb_path => "/usr/share/logstash/data/sincedb.txt"  # Persistent file to remember ingestion state
    codec => json                             # Parse each line as a JSON object
    discover_interval => 15
  }
}

filter {
  # Extract first value from the array
  ruby {
    code => "
        lat = event.get('[V2Locations][LocationLatitude]')
        lon = event.get('[V2Locations][LocationLongitude]')
        
        if lat and lon
          locations = []
          lat.each_with_index do |lat_value, index|
            lon_value = lon[index]
            if lat_value and lon_value
              locations << [lon_value.to_f, lat_value.to_f]
            end
          end
          event.set('location', locations) unless locations.empty?
        end
      "
  }

}
output {
  elasticsearch {
    hosts => ["https://es01:9200"]          # Replace <ES_IP> with your Elasticsearch container's IP (e.g., 172.20.0.2)
    index => "gkg"                    # Replace <INDEX_NAME> with your desired index name (e.g., gdelt_test)
    user => "elastic"                        # Replace <ES_USER> with your Elasticsearch username (e.g., elastic)
    password => "changeme"                # Replace <ES_PASSWORD> with your Elasticsearch password
    ssl_certificate_verification => false     # Disable certificate verification (for self-signed certs)

  # Manage the template directly in the config
    manage_template => true
    template_overwrite => true
    template => "/usr/share/logstash/template.json"  # Path to template file
  }
}
